{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55c5c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import pysam \n",
    "from Bio import SeqIO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8872af",
   "metadata": {},
   "source": [
    "## Inputs: \n",
    "\n",
    "`BAM` files with the sequencing aligned to the SSPE reference. \n",
    "\n",
    "`fasta` file for the SSPE reference made from all tissues. \n",
    "\n",
    "`csv` file with the variants labeled by whether they're genome-1 or genome-2 \n",
    "\n",
    "Eventually, these will all be inputs in the `Snakemake` pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec62f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bam files - will be supplied by snakemake \n",
    "bams = list()\n",
    "for root, dirs, files in os.walk(\"../../results/realigned/\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".bam\"):\n",
    "             bams.append(os.path.join(root, file))\n",
    "                \n",
    "# Base inputs for analysis\n",
    "ref_path = \"../../config/ref/MeVChiTok-SSPE.fa\" \n",
    "contig = \"MeVChiTok\"\n",
    "minimum_qual = 25\n",
    "\n",
    "# Import the dataframe with mutations labled by identity\n",
    "snps_path = \"../../results/spatial/labeled_variants.csv\" # Path to the major haplotypes\n",
    "snps_df = pd.read_csv(snps_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49aed4d",
   "metadata": {},
   "source": [
    "## Functions \n",
    "\n",
    "Main functions need to run the analysis – these include phasing reads and several helper functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154c12b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_read(read):\n",
    "    \"\"\"\n",
    "    Helper function to decide what reads should\n",
    "    be keep when parsing alignment file with `pysam`. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    read : AlignedSegment\n",
    "        read from alignment file parsed with `pysam`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True/False if read should be included\n",
    "        \n",
    "    \"\"\"\n",
    "    # Exclude Quality Failures\n",
    "    if read.is_qcfail:\n",
    "        return False\n",
    "    # Exclude Secondary Mappings\n",
    "    if read.is_secondary:\n",
    "        return False\n",
    "    # Exclude Unmapped Reads\n",
    "    if read.is_unmapped:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d98b7",
   "metadata": {},
   "source": [
    "## Testing; 1, 2, 3 ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44400112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_variants(SNPs_df, bampath, contig, maxdepth = 500):\n",
    "    \n",
    "    ## ===== Format inputs and get SNP list ===== ##\n",
    "\n",
    "    SNPs_set = set(pair for pair in zip(SNPs_df.POS, SNPs_df.ALT))                   \n",
    "    \n",
    "    ## ===== Move through the BAM file and get haplotypes ===== ##\n",
    "    \n",
    "    # Save the haplotypes in a dictionary\n",
    "    haplotype_dict = {}\n",
    "\n",
    "    # Get the start and stop\n",
    "    start = sorted([pos for pos, alt in SNPs_set])[0]\n",
    "    stop = sorted([pos for pos, alt in SNPs_set])[-1]\n",
    "\n",
    "    # Open alignment with pysam\n",
    "    with pysam.AlignmentFile(bampath, \"rb\") as bamfile:\n",
    "\n",
    "        # Get the pileup column for a specific region\n",
    "        for pileupcolumn in bamfile.pileup(contig, max_depth = maxdepth, start = start, stop = stop, stepper = 'nofilter'):\n",
    "\n",
    "            # Check the if the position has a target SNP (converted to 0-indexed)\n",
    "            if pileupcolumn.pos in [pos-1 for pos, alt in SNPs_set]:\n",
    "\n",
    "                # Iterate over every alignment in the pileup column. \n",
    "                for pileupread in pileupcolumn.pileups:\n",
    "\n",
    "                    # Check if the read is valid and can be parsed\n",
    "                    if check_read(pileupread.alignment) and not pileupread.is_del and not pileupread.is_refskip:\n",
    "\n",
    "                        # Save the query name\n",
    "                        qname = pileupread.alignment.query_name\n",
    "                        \n",
    "                        # Save the 1-indexed position\n",
    "                        pos = pileupcolumn.pos + 1\n",
    "\n",
    "                        # Save the base at that position in the read\n",
    "                        alt = pileupread.alignment.query_sequence[pileupread.query_position]\n",
    "\n",
    "                        # Check if this read has the SNP or not\n",
    "                        if (pos, alt) in SNPs_set:\n",
    "                            phase = 1 # The read has the SNP\n",
    "\n",
    "                        else:\n",
    "                            phase = 0 # The read doesn't have the SNP\n",
    "\n",
    "                        # Add the readname to the dictionary  \n",
    "                        if qname in haplotype_dict.keys():\n",
    "                            haplotype_dict[qname].append((pos, phase, alt)) \n",
    "                        else:\n",
    "                            haplotype_dict[qname] = [(pos, phase, alt)]\n",
    "                     \n",
    "    ## ===== Convert the haplotype dictionary to a dataframe filling in missings ===== ##\n",
    "    \n",
    "    # Save the haplotypes with missing values (not covered by reads) filled\n",
    "    completed_haplotype_dict = {}\n",
    "\n",
    "    # Iterate over the haplotype dictionary created above\n",
    "    for qname, alleles in haplotype_dict.items():\n",
    "        \n",
    "        # Make a dictionary to fill with observed SNPs for each read\n",
    "        aa_dict = {tup:\"-\" for tup in SNPs_set}\n",
    "        \n",
    "        # Iterate over all observed alleles\n",
    "        for allele in alleles:\n",
    "            \n",
    "            # If it's 1, then an allele was observed\n",
    "            if allele[1] == 1:\n",
    "                # Add this observation based on the key\n",
    "                aa_dict[(allele[0], allele[2])] = 1\n",
    "            # If it's a wild type allele \n",
    "            elif allele[1] == 0:\n",
    "                # Check every possible wt allele\n",
    "                for key in aa_dict.keys():\n",
    "                    # Check by position\n",
    "                    if key[0] == allele[0]:\n",
    "                        # If it's the same positon add a 0\n",
    "                        aa_dict[key] = 0\n",
    "\n",
    "        # Add this populated dictionary to the haplotype dictionary\n",
    "        completed_haplotype_dict[qname] = aa_dict\n",
    "\n",
    "    \n",
    "    # Convert this dicitonary into a dataframe and take the transpose\n",
    "    haplotype_df = pd.DataFrame(completed_haplotype_dict).T\n",
    "    \n",
    "    # Replace the '-' with 'NaN'\n",
    "    haplotype_df = haplotype_df.replace('-', np.nan)\n",
    "    \n",
    "    # Return the phased SNP df\n",
    "    return haplotype_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "82a5c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_variants(bampath, snps):\n",
    "    \"\"\"\n",
    "    Get the phase of variants by making a dictionary keyed by \n",
    "    read name and add allele counts for all polymorphic sites.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    bampath: str\n",
    "        Path to a BAM file to phase variants for.\n",
    "    \n",
    "    snps: list\n",
    "        A sorted list of the SNPs to phase.\n",
    "    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    pandas.DataFrame\n",
    "        DataFrame with the pairwise phase of all targeted SNPs\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Searchable set of alternative alleles at each position \n",
    "    alt_alleles = set((pos, alt) for ref, pos, alt in snps)\n",
    "    # Searchable set of reference alleles at each position \n",
    "    ref_alleles = set((pos, ref) for ref, pos, alt in snps)\n",
    "    \n",
    "    # First and last position to visit in the pileup column\n",
    "    start = snps[0][1]\n",
    "    stop = snps[-1][1]\n",
    "    \n",
    "    # Empty dict to store qnames\n",
    "    qnames = defaultdict(list)\n",
    "    # Empty dict to store snp pairs\n",
    "    phased = defaultdict(list)\n",
    "    \n",
    "    ## ==== Go through the bam file and identify haplotypes ==== ##\n",
    "    \n",
    "    # Open the alignment file\n",
    "    with pysam.AlignmentFile(bampath, \"rb\") as bamfile:\n",
    "        \n",
    "        # Iterate over the pileup column at each position\n",
    "        for pileupcolumn in bamfile.pileup(stepper = 'nofilter',\n",
    "                                           flag_filter = 0,\n",
    "                                           min_base_quality = 25,\n",
    "                                           start = start,\n",
    "                                           stop = stop,):\n",
    "            \n",
    "            # Check if the position contains a polymorphic position\n",
    "            if pileupcolumn.reference_pos + 1 in set(pos for ref, pos, alt in snps):\n",
    "                \n",
    "                # Iterate over each read in the pileup column \n",
    "                for pileupread in pileupcolumn.pileups:\n",
    "                    \n",
    "                    # Check that it's a good read - no deletions, qfails, or skips\n",
    "                    if check_read(pileupread.alignment) and not pileupread.is_del and not pileupread.is_refskip:\n",
    "\n",
    "                        # Save the read name\n",
    "                        qname = pileupread.alignment.query_name\n",
    "\n",
    "                        # Save the 1-indexed position\n",
    "                        position = pileupcolumn.pos + 1\n",
    "\n",
    "                        # Save the base at that position in the read\n",
    "                        allele = pileupread.alignment.query_sequence[pileupread.query_position]\n",
    "\n",
    "                        # Check if this read has the SNP or not - assuming bialleleic! \n",
    "                        if (position, allele) in alt_alleles:\n",
    "                            phase = 1 # The read has the alt allele at this position\n",
    "\n",
    "                        elif (position, allele) in ref_alleles:\n",
    "                            phase = 0 # The read has the ref allele at this position\n",
    "                        else:\n",
    "                            continue \n",
    "\n",
    "                        # Add the qname to the dictionary along with phase at position \n",
    "                        qnames[qname].append((position, phase, allele))\n",
    "\n",
    "    ## ==== Collate haplotypes and count for all SNP paris observed ==== ##\n",
    "    \n",
    "    for qname, alleles in qnames.items(): \n",
    "\n",
    "        # Can't phase anything with a single SNP\n",
    "        if len(set(alleles)) == 1: \n",
    "            continue \n",
    "\n",
    "        haplotype = defaultdict(set)\n",
    "        for pos, phase, allele in alleles:\n",
    "            haplotype[pos].add(phase)\n",
    "\n",
    "        # Don't use reads with read pairs that disagree \n",
    "        for phases in haplotype.values():\n",
    "            if len(phases) > 1:\n",
    "                continue\n",
    "\n",
    "        # Get a list of allele observations for this read\n",
    "        allele_obsvs = sorted([(position, list(phase)[0])\n",
    "                               for position, phase \n",
    "                               in haplotype.items()], key = lambda x: x[0])\n",
    "\n",
    "        # Get the phases of all combinations represented on this read\n",
    "        for allele_one, allele_two in itertools.combinations(allele_obsvs, 2): \n",
    "\n",
    "            allele_pair = (allele_one[0], allele_two[0])\n",
    "\n",
    "            phasing = f\"{allele_one[1]}{allele_two[1]}\"\n",
    "\n",
    "            # Add them to a dictionary indexed by the combination of positions \n",
    "            phased[allele_pair].append(phasing)\n",
    "\n",
    "    # Count the haplotypes for each pair of positions with overlaping reads \n",
    "    counts = {comp: Counter(haps) for comp, haps in phased.items()}\n",
    "\n",
    "    # Convert to a dataframe \n",
    "    counts_df = (pd.DataFrame(counts)\n",
    "                 .T\n",
    "                 .fillna(0)\n",
    "                 .reset_index()\n",
    "                 .rename(columns = {\"level_0\": \"snp_1\", \"level_1\": \"snp_2\"})\n",
    "                 .sort_values(by=['snp_1', 'snp_2'])\n",
    "    )\n",
    "\n",
    "    # Check that there are no redundant pairs - these would need to be combined \n",
    "    assert len(set(\n",
    "        Counter(\n",
    "            tuple(sorted((pos_1, pos_2))) \n",
    "            for pos_1, pos_2 \n",
    "            in zip(counts_df.snp_1, counts_df.snp_2))\n",
    "        .values())) == 1\n",
    "\n",
    "    return counts_df\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84c97fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all SNPs including the reference allele - assume all sites are biallelic \n",
    "snps_list = sorted(\n",
    "                list(\n",
    "                    {(REF, POS, ALT) for REF, POS, ALT in\n",
    "                     zip(snps_df.REF, snps_df.POS, snps_df.ALT)}\n",
    "                ),\n",
    "                key = lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d56427d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning reads for Frontal Cortex 3\n",
      "Assigning reads for Internal Capsule\n",
      "Assigning reads for Brain Stem\n",
      "Assigning reads for Cerebellum Nucleus\n",
      "Assigning reads for Frontal Cortex 1\n",
      "Assigning reads for UBS\n",
      "Assigning reads for Parietal Lobe\n",
      "Assigning reads for Midbrain\n",
      "Assigning reads for Occipital Lobe\n",
      "Assigning reads for Temporal Lobe\n",
      "Assigning reads for Frontal Cortex 2\n"
     ]
    }
   ],
   "source": [
    "phase_list = []\n",
    "\n",
    "for bam in bams:\n",
    "    \n",
    "    tissue = \" \".join(os.path.basename(bam).split(\".\")[0].split(\"_\"))\n",
    "    print(f'Assigning reads for {tissue}')\n",
    "    \n",
    "    phase_df = phase_variants(bam, snps_list)\n",
    "    phase_df[\"Tissue\"] = tissue\n",
    "    \n",
    "    phase_list.append(phase_df)\n",
    "    \n",
    "final_df = pd.concat(phase_list)\n",
    "final_df.to_csv(\"../../config/snp_pairs.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "17939f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snp_1</th>\n",
       "      <th>snp_2</th>\n",
       "      <th>00</th>\n",
       "      <th>10</th>\n",
       "      <th>01</th>\n",
       "      <th>11</th>\n",
       "      <th>Tissue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>96</td>\n",
       "      <td>6402.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frontal Cortex 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>152</td>\n",
       "      <td>5180.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frontal Cortex 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>42</td>\n",
       "      <td>167</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frontal Cortex 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>242</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frontal Cortex 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>260</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frontal Cortex 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <td>15382</td>\n",
       "      <td>15799</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frontal Cortex 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21005</th>\n",
       "      <td>15382</td>\n",
       "      <td>15855</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frontal Cortex 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15795</td>\n",
       "      <td>15799</td>\n",
       "      <td>7144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frontal Cortex 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>15795</td>\n",
       "      <td>15855</td>\n",
       "      <td>2989.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frontal Cortex 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3809</th>\n",
       "      <td>15799</td>\n",
       "      <td>15855</td>\n",
       "      <td>3226.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frontal Cortex 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248374 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       snp_1  snp_2      00    10     01   11            Tissue\n",
       "0         42     96  6402.0  18.0    1.0  0.0  Frontal Cortex 3\n",
       "1         42    152  5180.0  15.0  162.0  1.0  Frontal Cortex 3\n",
       "79        42    167   115.0   2.0    1.0  0.0  Frontal Cortex 3\n",
       "3         42    242    78.0   0.0    0.0  0.0  Frontal Cortex 3\n",
       "4         42    260    77.0   0.0    0.0  0.0  Frontal Cortex 3\n",
       "...      ...    ...     ...   ...    ...  ...               ...\n",
       "20995  15382  15799    22.0   0.0    0.0  0.0  Frontal Cortex 2\n",
       "21005  15382  15855     5.0   0.0    0.0  0.0  Frontal Cortex 2\n",
       "3      15795  15799  7144.0   1.0    5.0  0.0  Frontal Cortex 2\n",
       "3808   15795  15855  2989.0   1.0   24.0  0.0  Frontal Cortex 2\n",
       "3809   15799  15855  3226.0   1.0   24.0  0.0  Frontal Cortex 2\n",
       "\n",
       "[248374 rows x 7 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47a5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
